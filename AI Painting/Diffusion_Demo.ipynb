{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhb9ysqqOkiN",
        "outputId": "3d8e3d4a-dd92-4109-9642-370c9e8bfbe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libcudnn8 is already the newest version (8.1.0.77-1+cuda11.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/divamgupta/stable-diffusion-tensorflow --upgrade --quiet\n",
        "!pip install tensorflow tensorflow_addons ftfy --upgrade --quiet\n",
        "!pip install -q gradio --quiet\n",
        "!pip install opencv-python\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_diffusion_tf.stable_diffusion import StableDiffusion\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "\n",
        "generator = StableDiffusion(\n",
        "    img_height=512,\n",
        "    img_width=512,\n",
        "    jit_compile=False,  # You can try True as well (different performance profile)\n",
        ")"
      ],
      "metadata": {
        "id": "LOEpUKHGPR0w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img(input_img, input_prompt='Motoko Kusanagi, Ghost in the shell', n_steps='50'):\n",
        "  if type(input_img) is not str:\n",
        "    cv.imwrite('hehe.jpg', input_img)\n",
        "    input_img = 'hehe.jpg'\n",
        "\n",
        "  input_prompt = str(input_prompt)\n",
        "\n",
        "  n_steps = int(n_steps)\n",
        "  if n_steps <= 25:\n",
        "    n_steps = 25\n",
        "  if n_steps >= 100:\n",
        "    n_steps = 100\n",
        "\n",
        "  return generator.generate(\n",
        "      input_prompt,\n",
        "      num_steps=n_steps,\n",
        "      unconditional_guidance_scale=7.5,\n",
        "      temperature=1,\n",
        "      batch_size=1,\n",
        "      input_image=input_img,\n",
        "      input_image_strength=0.8\n",
        "  )[0]"
      ],
      "metadata": {
        "id": "BDikjfStPvS0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Let's See What AI Can Draw\")\n",
        "    prt = gr.Textbox(label=\"输入一段话描述想要画出的作品，只限英文\")\n",
        "    with gr.Row():\n",
        "      input_img = gr.Image(label='添加你的草稿（随便都行）')\n",
        "      output_img = gr.Image()\n",
        "    n_steps = gr.Textbox(label=\"迭代次数(25~100)，越大作品质量越高\")\n",
        "    btn = gr.Button(\"生成\")\n",
        "    btn.click(fn=get_img, inputs=[input_img, prt, n_steps], outputs=output_img)\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "aFimYPnAQrrQ",
        "outputId": "cba3f0e8-73e2-4e00-dd19-cd8812677fa8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://ee2432a1dc899cd1.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ee2432a1dc899cd1.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f71124c3c10>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://ee2432a1dc899cd1.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# demo.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c4Rm_bUbHBC",
        "outputId": "06a2980e-60c8-4bc3-df97-eb9bd43121df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0   1: 100%|██████████| 53/53 [01:05<00:00,  1.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing server running on port: 7860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4EXRE5bIe7RH"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}